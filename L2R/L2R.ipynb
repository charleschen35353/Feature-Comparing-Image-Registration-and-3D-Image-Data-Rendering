{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 620\n",
    "IMG_HEIGHT = 877\n",
    "IMG_CHN = 3\n",
    "NUM_F_POINTS = 5000\n",
    "NUM_MATCHES = 2000\n",
    "BBOX_LENGTH = 21     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Batch processing of cv2 non-learning based method\n",
    "def sigmoid(x):\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    return s\n",
    "\n",
    "def extract_features(ref_image, sns_image):\n",
    "    # Create ORB detector with 5000 features. \n",
    "\n",
    "    ref_image = cv2.cvtColor(ref_image, cv2.COLOR_BGR2GRAY) \n",
    "    sns_image = cv2.cvtColor(sns_image, cv2.COLOR_BGR2GRAY) \n",
    "    orb_detector = cv2.ORB_create(5000) \n",
    "    kp1, d1 = orb_detector.detectAndCompute(ref_image, None) \n",
    "    kp2, d2 = orb_detector.detectAndCompute(sns_image, None) \n",
    "    return [kp1,kp2,d1,d2]\n",
    "\n",
    "def extract_feature_batch(refs, sns):\n",
    "    output = [[],[],[],[]]\n",
    "    for i in range(refs.shape[0]):\n",
    "        out = extract_features(refs[i], sns[i])\n",
    "        for j in range(4):\n",
    "            output[j].append(out[j])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def batch_match(d1s, d2s):\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "    matches = []\n",
    "\n",
    "    for i in range(len(d1s)):\n",
    "        matches.append(matcher.match(d1s[i], d2s[i]))\n",
    "    return matches\n",
    "\n",
    "def validate_match(matches):\n",
    "    for i in range(len(matches)):\n",
    "        matches[i].sort(key = lambda x: x.distance)\n",
    "        matches[i] = matches[i][:int(len(matches)*60)]\n",
    "    return matches\n",
    "\n",
    "def calc_homographies(kp1s, kp2s, matches):\n",
    "    # Define empty matrices of shape no_of_matches * 2. \n",
    "    homographies = []\n",
    "    \n",
    "    temp = matches\n",
    "    matches = []\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i] != []:\n",
    "            matches.append(list(filter(None, temp[i])))\n",
    "            \n",
    "    matches = validate_match(matches)\n",
    "    \n",
    "    for i in range(len(matches)):\n",
    "        p1 = np.zeros((len(matches[i]), 2)) \n",
    "        p2 = np.zeros((len(matches[i]), 2)) \n",
    "        for j in range(len(matches[i])):\n",
    "            p1[j, :] = kp1s[i][matches[i][j].queryIdx].pt \n",
    "            p2[j, :] = kp2s[i][matches[i][j].trainIdx].pt \n",
    "        homography, _ = cv2.findHomography(p1, p2, cv2.RANSAC) \n",
    "        homographies.append(homography)\n",
    "    return homographies\n",
    "\n",
    "def register_images(sns_imgs, homographies, img_size = (IMG_WIDTH,IMG_HEIGHT), save = False):\n",
    "    # Use this matrix to transform the \n",
    "    # colored image wrt the reference image. \n",
    "    transformed_imgs = []\n",
    "    for i in range(sns_imgs.shape[0]):\n",
    "        transformed_img = cv2.warpPerspective(sns_imgs[i], \n",
    "                            homographies[i], img_size) \n",
    "        if save: \n",
    "            cv2.imwrite('aligned_{}.jpg'.format(i), transformed_img) \n",
    "        \n",
    "        transformed_imgs.append(transformed_img)\n",
    "    return transformed_imgs\n",
    "\n",
    "def visualize_matches(ref_imgs, sns_imgs, kp1s, kp2s, matches):\n",
    "    for i in range(ref_imgs.shape[0]):\n",
    "        imMatches = cv2.drawMatches(ref_imgs[i], kp1s[i], sns_imgs[i], kp2s[i], matches[i], None)\n",
    "        cv2.imwrite(\"matches_{}.jpg\".format(i), imMatches)\n",
    "    \n",
    "    \n",
    "def get_alignment_matrix(kprs, kpss, drs, dss):\n",
    "    '''\n",
    "    Inputs\n",
    "        kprs: F keypoints for each reference(query) image of shape N*F*3 with X,Y,Size\n",
    "        kpss: F keypoints for each sensed(train) image of shape N*F*3 with X,Y,Size\n",
    "        drs: F feature descriptors for each reference(query) image of shape N*F*32 \n",
    "        dss: F feature descriptors for each sensed(train) image of shape N*F*32 \n",
    "    Output\n",
    "        aligned feature points and correlated distance of size N*f*7 X1,Y1,Size1, X2, Y2, Size2, Distance\n",
    "    '''\n",
    "\n",
    "    alignment_matrices = None\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "    for i in range(kprs.shape[0]):\n",
    "        results = matcher.match(d1s[i], d2s[i])\n",
    "        aligned = []\n",
    "        for r in results:\n",
    "            if len(aligned) >= NUM_MATCHES: break\n",
    "            temp = np.concatenate((kprs[i][r.queryIdx], kpss[i][r.trainIdx]))\n",
    "            aligned.append(np.concatenate((temp, [r.distance])))\n",
    "            \n",
    "        while len(aligned) < NUM_MATCHES:\n",
    "            aligned.append([0,0,0,0,0,0,0])\n",
    "            \n",
    "        aligned = np.array([aligned])\n",
    "        if alignment_matrices is None:\n",
    "            alignment_matrices = aligned\n",
    "        else:\n",
    "            alignment_matrices = np.vstack((alignment_matrices, aligned))\n",
    "            \n",
    "    #sample alignment_matrix\n",
    "    alignment_matrices = np.rint(alignment_matrices).astype(np.uint32)\n",
    "    return alignment_matrices\n",
    "    \n",
    "    \n",
    "def test_cv2_batch(dl):\n",
    "    refs, sns = dl.load_image()\n",
    "    kp1s, kp2s, d1s,d2s = extract_feature_batch(refs,sns)\n",
    "    matches = batch_match(d1s, d2s)\n",
    "    \n",
    "    visualize_matches(refs, sns, kp1s, kp2s, matches)\n",
    "    homos = calc_homographies(kp1s, kp2s, matches)\n",
    "    imgs = register_images(sns, homos)\n",
    "    for i in range(6):\n",
    "            cv2.imwrite(\"registered_cv2{}.jpg\".format(i), imgs[i])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_F_POINTS = 2000\n",
    "\n",
    "def extract_feature_coordinates(ref_image, sns_image):\n",
    "    # Create ORB detector with 5000 features. \n",
    "    ref_image = cv2.cvtColor(ref_image, cv2.COLOR_BGR2GRAY) \n",
    "    sns_image = cv2.cvtColor(sns_image, cv2.COLOR_BGR2GRAY) \n",
    "    orb_detector = cv2.ORB_create(NUM_F_POINTS) \n",
    "    kp1, d1 = orb_detector.detectAndCompute(ref_image, None) \n",
    "    kp2, d2 = orb_detector.detectAndCompute(sns_image, None) \n",
    "    kp1_np, kp2_np = [], []\n",
    "    for i in range(NUM_F_POINTS):\n",
    "        if i < len(kp1):\n",
    "            kp1_np.append([kp1[i].pt[0],kp1[i].pt[1], kp1[i].size ] )\n",
    "        else:\n",
    "            kp1_np.append([0,0,0])\n",
    "            d1 = np.vstack((d1, [np.zeros(32, dtype = np.uint8 )]))\n",
    "            \n",
    "        if i < len(kp2):\n",
    "            kp2_np.append([kp2[i].pt[0],kp2[i].pt[1], kp2[i].size ] )\n",
    "        else:\n",
    "            kp2_np.append([0,0,0])\n",
    "            d2 = np.vstack((d2, [np.zeros(32,dtype = np.uint8 )]))\n",
    "        \n",
    "    kp1_np, kp2_np = np.array(kp1_np) , np.array(kp2_np)\n",
    "\n",
    "    return [kp1_np, kp2_np, d1, d2]\n",
    "\n",
    "def extract_feature_coor_batch(refs, sns):\n",
    "    output = []\n",
    "    for i in range(refs.shape[0]):\n",
    "        out = extract_feature_coordinates(refs[i], sns[i])\n",
    "        for j in range(4):\n",
    "            if len(output) < 4:\n",
    "                output.append(np.expand_dims(out[j], axis=0))\n",
    "            else: \n",
    "                output[j] = np.vstack( (output[j],np.expand_dims(out[j], axis=0)) )\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def extract_match_patches(ref_imgs, sns_imgs, kprs, kpss, drs, dss):\n",
    "    '''\n",
    "    output: N * NUM_MATCHES * 2 * PATCH_H * PATCH_W * CHN Example:(6, 500, 2, 6, 6, 3)\n",
    "    '''\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "    patches, matches = [], []\n",
    "    for i in range(kprs.shape[0]):\n",
    "        results = matcher.match(drs[i], dss[i])\n",
    "\n",
    "        patch = []\n",
    "        match = []\n",
    "        for r in results:\n",
    "            pair = []\n",
    "            match_p = []\n",
    "            if len(patch) >= NUM_MATCHES: break\n",
    "            x, y, dis = kprs[i][r.queryIdx].astype(np.uint32)\n",
    "            if  x-(BBOX_LENGTH-1) > 0 and y-(BBOX_LENGTH-1) > 0 \\\n",
    "                and x+(BBOX_LENGTH-1)/2 < IMG_WIDTH and y+(BBOX_LENGTH-1)/2 < IMG_HEIGHT:\n",
    "                pair.append(ref_imgs[i][y-int((BBOX_LENGTH-1)/2):y+int((BBOX_LENGTH-1)/2)\\\n",
    "                                       ,x-int((BBOX_LENGTH-1)/2):x+int((BBOX_LENGTH-1)/2)])\n",
    "                \n",
    "            x, y, dis = kpss[i][r.trainIdx].astype(np.uint32)\n",
    "            if  x-(BBOX_LENGTH-1) > 0 and y-(BBOX_LENGTH-1) > 0 \\\n",
    "                and x+(BBOX_LENGTH-1)/2 < IMG_WIDTH and y+(BBOX_LENGTH-1)/2 < IMG_HEIGHT:\n",
    "                pair.append(sns_imgs[i][y-int((BBOX_LENGTH-1)/2):y+int((BBOX_LENGTH-1)/2)\\\n",
    "                                       ,x-int((BBOX_LENGTH-1)/2):x+int((BBOX_LENGTH-1)/2)])\n",
    "                \n",
    "            if len(pair) == 2:\n",
    "                patch.append(np.array(pair))\n",
    "                match.append(r)\n",
    "                \n",
    "        while len(patch) < NUM_MATCHES:\n",
    "            patch.append(np.zeros((2,BBOX_LENGTH-1,BBOX_LENGTH-1, IMG_CHN)))\n",
    "            match.append(None)\n",
    "            \n",
    "        patch = np.array(patch)\n",
    "        patches.append(patch)\n",
    "        match = np.array(match)\n",
    "        matches.append(match)\n",
    "\n",
    "        \n",
    "    patches = np.array(patches)\n",
    "    matches = np.array(matches)   \n",
    "\n",
    "    return [patches[:,:,0,:,:,:], patches[:,:,1,:,:,:], matches]\n",
    "    \n",
    "\n",
    "def get_match_info(refs,snss):\n",
    "    \"\"\"\n",
    "    returns in 255 scale\n",
    "    \"\"\"\n",
    "    kprs,kpss, drs, dss = extract_feature_coor_batch(refs,snss)\n",
    "    p_ref, p_sns, matches =  extract_match_patches(refs, snss, kprs, kpss, drs, dss)\n",
    "    return [p_ref, p_sns, matches, kprs, kpss]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\ndef test_loader():\\n    dl = Dataloader(\"./test_data\",\"./test_data\")\\n    x,y,matches,imgs= dl.load_image()\\n    refs, sns = [] , []\\n    for r,s in imgs:\\n        refs.append(r)\\n        sns.append(s)\\n    refs = np.array(refs)\\n    sns = np.array(sns)\\n    print(refs.shape)\\n    \\n    p1,p2,c1,c2 = get_match_info(refs,sns)\\n    visualize_corresponding_patches(p1, p2)\\n    visualize_coords(refs,c1)\\n    \\n    p1,p2,matches, kprs,kpss = get_model_inputs(refs,sns)\\n    print(p1.shape)\\n    print(matches.shape)\\n    print(kprs.shape)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_generator_multiple(generator, path, batch_size = 16, img_height = IMG_HEIGHT, img_width = IMG_WIDTH):\n",
    "\n",
    "        gen_ref = generator.flow_from_directory(path,\n",
    "                                              classes = [\"ref\"],\n",
    "                                              target_size = (img_height,img_width),\n",
    "                                              batch_size = batch_size,\n",
    "                                              shuffle=False, \n",
    "                                              seed=7)\n",
    "\n",
    "        gen_sns = generator.flow_from_directory(path,\n",
    "                                              classes = [\"sns\"],\n",
    "                                              target_size = (img_height,img_width),\n",
    "                                              batch_size = batch_size,\n",
    "                                              shuffle=False, \n",
    "                                              seed=7)\n",
    "        while True:\n",
    "                X1i = gen_ref.next()\n",
    "                X2i = gen_sns.next()\n",
    "                x,y,matches, _, _ = get_model_inputs(X1i[0].astype(np.uint8), X2i[0].astype(np.uint8))\n",
    "                \n",
    "                yield [ X1i[0].astype(np.uint8), X2i[0].astype(np.uint8) ], x #Yield both images and their mutual label\n",
    "                \n",
    "class Dataloader:\n",
    "    def __init__(self, train_path, test_path, batch_size = 16):\n",
    "        \n",
    "        train_imgen = keras.preprocessing.image.ImageDataGenerator()\n",
    "        test_imgen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "        self.train_generator = generate_generator_multiple(generator=train_imgen,\n",
    "                                               path = str(train_path),\n",
    "                                               batch_size=batch_size)       \n",
    "\n",
    "        self.test_generator = generate_generator_multiple(test_imgen,\n",
    "                                              path = str(test_path),\n",
    "                                              batch_size=batch_size)              \n",
    "\n",
    "        \n",
    "    def load_image(self, test = False):\n",
    "        if test:\n",
    "            return next(self.test_generator)[0]\n",
    "        else:\n",
    "            return next(self.train_generator)[0]\n",
    "    \n",
    "    def load_dl(self):\n",
    "        return [self.train_generator, self.test_generator]\n",
    "    \n",
    "    \n",
    "def get_model_inputs(refs,sns):\n",
    "    p_ref, p_sns, matches, kprs, kpss = get_match_info(refs, sns)\n",
    "    p_ref = (p_ref.astype(np.float32) / 255.0 ).reshape((p_ref.shape[0]*p_ref.shape[1],\\\n",
    "                                                        p_ref.shape[2], p_ref.shape[3], p_ref.shape[4]))\n",
    "    p_sns = (p_sns.astype(np.float32) / 255.0).reshape((p_sns.shape[0]*p_sns.shape[1],\\\n",
    "                                                        p_sns.shape[2], p_sns.shape[3], p_sns.shape[4]))\n",
    "    #matches = matches.reshape(matches.shape[0] * matches.shape[1])\n",
    "    return [p_ref, p_sns, matches, kprs, kpss]\n",
    "        \n",
    "def visualize_corresponding_patches(p1, p2):\n",
    "    for j in range(50):\n",
    "        vis = (np.concatenate((p1[0][j], p2[0][j]), axis=1))\n",
    "        cv2.imwrite(\"patch pair {}.jpg\".format(j), vis)\n",
    "        \n",
    "def visualize_coords(img, c):\n",
    "    for j in range(500):\n",
    "        cv2.circle(img[0], (c[0][j][0], c[0][j][1]) , 1, (0, 0, 255), -1)\n",
    "    cv2.imwrite(\"New feture img.jpg\", img[0])\n",
    "        \n",
    "'''    \n",
    "def test_loader():\n",
    "    dl = Dataloader(\"./test_data\",\"./test_data\")\n",
    "    x,y,matches,imgs= dl.load_image()\n",
    "    refs, sns = [] , []\n",
    "    for r,s in imgs:\n",
    "        refs.append(r)\n",
    "        sns.append(s)\n",
    "    refs = np.array(refs)\n",
    "    sns = np.array(sns)\n",
    "    print(refs.shape)\n",
    "    \n",
    "    p1,p2,c1,c2 = get_match_info(refs,sns)\n",
    "    visualize_corresponding_patches(p1, p2)\n",
    "    visualize_coords(refs,c1)\n",
    "    \n",
    "    p1,p2,matches, kprs,kpss = get_model_inputs(refs,sns)\n",
    "    print(p1.shape)\n",
    "    print(matches.shape)\n",
    "    print(kprs.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "def feature_extractor_model():\n",
    "    feature_extractor_input = keras.Input(shape=( (2*int((BBOX_LENGTH-1)/2))**2*IMG_CHN, ) )\n",
    "    print(feature_extractor_input.shape)\n",
    "    x = layers.Flatten()(feature_extractor_input)\n",
    "    x = layers.Dense(128 ,activation='relu',kernel_initializer= keras.initializers.he_normal())(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(64, activation='relu',kernel_initializer= keras.initializers.he_normal())(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    feature_extractor_output = layers.Dropout(0.2)(x)\n",
    "    feature_extractor = keras.Model(feature_extractor_input,feature_extractor_output, name='feature_extractor')\n",
    "    feature_extractor.summary()\n",
    "    return feature_extractor\n",
    "\n",
    "def classifier_model():\n",
    "    classification_input = keras.Input(shape=( 128, ) )\n",
    "    x = layers.Dense(64 ,activation='relu',kernel_initializer = keras.initializers.he_normal())(classification_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    classification_output = layers.Dense(1 ,activation='softmax',kernel_initializer=keras.initializers.he_normal())(x)\n",
    "    classifier = keras.Model(classification_input,classification_output, name='classifier')\n",
    "    classifier.summary()\n",
    "    return classifier\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "def patch_dist(p1,p2):\n",
    "    return np.mean(((p1 - p2)**2)**0.5)\n",
    "\n",
    "def get_central_coor(patch,img):\n",
    "    W,H = patch.shape[0], patch.shape[1]\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            print(\"{} {}\".format(i,j))\n",
    "            if i+W < img.shape[0] and j+H < img.shape[1] and patch_dist(img[i:i+W, j:j+H, :],patch) < 1:\n",
    "                return (i+W/2, j + H/2)\n",
    "            \n",
    "    print(\"patch does not exist in img.\")\n",
    "    return None\n",
    "\n",
    "class PatchRanker(keras.Model):\n",
    "    def __init__(self, name = \"patch_ranker\", **kwargs):\n",
    "        super(PatchRanker, self).__init__(name=name, **kwargs)\n",
    "        self.feature_extractor = feature_extractor_model()\n",
    "        self.classifier = classifier_model()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        zipped = inputs\n",
    "        refs, sns = [] ,[]\n",
    "        for r,s in imgs:\n",
    "            refs.append(r)\n",
    "            sns.append(s)\n",
    "        refs = np.array(refs)\n",
    "        sns = np.array(sns)\n",
    "        f_x = self.feature_extractor(x)\n",
    "        f_y = self.feature_extractor(y)\n",
    "        f_xy = tf.concat([f_x,f_y],1)\n",
    "        classified = self.classifier(f_xy)\n",
    "        pred = tf.reshape(classified, [-1, NUM_MATCHES, 1])\n",
    "        \n",
    "        inds = tf.argsort(pred, axis = 1)\n",
    "        selected_inds = tf.cast(tf.where(inds < 50, tf.ones_like(inds), tf.zeros_like(inds)), tf.float32 )[:,:,0] # 6*500*1\n",
    "        selected_matches = np.where( selected_inds.numpy() == 1.0, matches, np.zeros_like(matches)  )\n",
    "        good_matches = []\n",
    "        for i in range(selected_matches.shape[0]):\n",
    "            good_matches.append(selected_matches[i][selected_matches[i] != 0])\n",
    "\n",
    "        kprs, kpss, _, _ =  extract_feature_batch(refs,snss)\n",
    "        homo = calc_homographies(kprs, kpss, good_matches)\n",
    "        imgs = np.array(register_images(snss, homo))\n",
    "\n",
    "        for i in range(6):\n",
    "            cv2.imwrite(\"registered_cv2{}.jpg\".format(i), imgs[i])\n",
    "        print(\"registered!!\")\n",
    "        _, _, matches, kp1s, kp2s = get_match_info(refs, imgs)\n",
    "\n",
    "        feature_diss = []\n",
    "        coor_diss = []\n",
    "        \n",
    "        \n",
    "        for i in range(kp1s.shape[0]):\n",
    "            coor_dis = 0\n",
    "            feature_dis = 0\n",
    "            valid_count = 0\n",
    "            for r in matches[i]:\n",
    "                if r is None:\n",
    "                    continue\n",
    "                valid_count+=1\n",
    "                x1, y1, _ = kp1s[i][r.queryIdx]\n",
    "                x2, y2, _ = kp1s[i][r.trainIdx]\n",
    "                #print(\"({},{})\".format(x1,y1))\n",
    "                #print(\"({},{})\".format(x2,y2))\n",
    "                coor_dis += ((x1-x2)**2 + (y1-y2)**2)**0.5 #euc dist\n",
    "\n",
    "                feature_dis += r.distance\n",
    "    \n",
    "            coor_diss.append(coor_dis/valid_count)\n",
    "            feature_diss.append(feature_dis/valid_count)\n",
    "        \n",
    "        coor_diss = np.array(coor_diss)\n",
    "        feature_diss = np.array(feature_diss)\n",
    "    \n",
    "        \n",
    "        gt = []\n",
    "        for c_d, f_d in zip(coor_diss, feature_diss):\n",
    "            if (c_d < DIST_THRES and f_d < DIST_THRES):\n",
    "                gt.append(np.ones_like(pred[0]))\n",
    "            else:\n",
    "                gt.append(np.zeros_like(pred[0]))\n",
    "        gt = np.array(gt)\n",
    "        loss = np.sum((gt - pred)**2)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DNN model\n",
    "\n",
    "DIST_THRES = 20\n",
    "lr = 1e-3\n",
    "batch_size = 6\n",
    "trainset_size = 6\n",
    "testset_size = 6\n",
    "epochs = 100\n",
    "\n",
    "patch_ranker = PatchRanker()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "patch_ranker.compile(optimizer = optimizer)\n",
    "\n",
    "dl = Dataloader(train_path = \"./test_data\", test_path= \"./test_data\", batch_size = batch_size)\n",
    "#refs, sns = dl.load_image()\n",
    "#imgs = patch_ranker([refs,sns])\n",
    "#dl = Dataloader(train_path = \"./test_data\", test_path= \"./test_data\", batch_size = batch_size)\n",
    "train_generator, test_generator = dl.load_dl()\n",
    "patch_ranker.fit_generator(train_generator,\n",
    "                                steps_per_epoch=trainset_size/batch_size,\n",
    "                                epochs = epochs,\n",
    "                                validation_data = test_generator,\n",
    "                                validation_steps = testset_size/batch_size,\n",
    "                                use_multiprocessing = True,\n",
    "                                shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
